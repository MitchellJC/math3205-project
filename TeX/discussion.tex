% 15 min time limits
It should be emphasised that because our time constraints are were stricter robustness may have been greatly affected giving different results to the original paper, however we found that our results were already disparate without this factor. For example, the original paper was able to solve with patient sizes up to 100 without ever going over an average run-time of 200 seconds. This change in experimental setup should have allowed our models to still attain similar results.

% Implementation
One possible reason the results were not able to replicate the original paper was that undisclosed implementation techniques might have been used and been important for performance. Due to our testing of optimality and feasibility across models, it was thought that the modelling implementation was correct, meaning that our relatively poor results were mainly thought to be due to algorithm optimization. Caching sub-problems was used to get more performance out of our models but was not enough to give us results similar to~\cite{roshanaei2017propagating}. Caching was used to avoid repeated calculation for identical sub problems and did give immediate improvements in the prototyping stage. In Figure~\ref{fig:MPSPtime} it was shown that for larger patient sizes, average time in the sub problem was not disproportionatly larger than in the master problem. This does give some confidence that poor sub problem implementation was not the main bottleneck of performance, as about half or more of the time was spent in the master problem, handled by Gurobi. 

% Inefficiency of network
The network formulation was slower and less robust than the MIP formulation, even when not considering node and arc generation time. It was initially thought that this formulation could yield improvements as it had shown promising results as a prototype for a similar hard surgery allocation problem that was thought to have needed the Branch and Price algorithm\cite{DoulabiBranchPriceOR}. After collecting our results it was realised that the key reason that the network formulation performed well for the aforementioned problem was due to importance of surgery ordering. For the DORS problem we only care about packing operations into an OR, order is not important. For this reason, the permutational generation of arcs for different orderings of surgeries was mostly redundant making the network fundamentally inefficient at solving this problem compared to other methods, particularly the pure MIP. Surprisingly, even with this shortcoming the network model was still able to be more robust than some of the Benders' Decomposition implementations when solving to a 1\% gap.

% Callbacks not being able to use cuts on incumbents
By construction, the stronger LBBD cuts were able to leverage the structure of an iterative implementation which may have bottlenecked greater improvement from using the callback. LBBD2 and LBBD4 both try to leverage the fact that the current solution to the master problem is optimal. That is for both cuts, there is dependency on $\hat{Y}_{hd}$ to be an optimal lower bound for the problem. However, Gurobi callbacks are called at each \textit{incumbent} solution, as the lazy constraints must cut off new solutions as they are reached in the branch-and-bound tree and cannot retroactively remove old solutions that violate a lazy constraint. We can still apply cuts in a callback despite this, however it was speculated that some were redundant or that this may have caused sub problems to be needlessly solved. 

% Getting to a one percent gap fast


% Great performance of pure MIP.
The simple pure MIP performed much better compared to the other more involved models, and much better than the original paper's pure MIP from the perspective of a 1\% gap. This may have been due to the simplicity of the model and furthermore of implementation. Very little model-critical code was implemented for the pure MIP besides the utilization of Gurobi classes and methods, which are all rigidly defined by that package and its documentation. This means that chance of introducing a logic or optimization error was much lower. This very well could have been the main driver of this model's success in our results. Alternatively, the great performance of the pure MIP could be due to the ongoing improvements being made to Gurobi's solver. Gurobi has gone through 3 major versions since the release of~\cite{roshanaei2017propagating},  in the latest major release alone it reports a 13\% speed improvement on its test MIP problems\cite{gurobiBragging}. The hardware difference between the original paper would also be a highly significant factor with~\cite{roshanaei2017propagating} running models on a Windows XP computer with an
Intel(R) Core(TM)2 Duo 3.00 gigahertz CPU with 8 gigabytes RAM. Other than these reasons the pure MIP may just be the best model out of those tested for the DORS problem and the specific data used for our tests. 